\chapter{Experimental Setup}\label{chapter:second_real_chapter}

\section{Implementation details}
\subsection{Dataset}
\paragraph{COCO~\cite{lin2015microsoftcococommonobjects}} is a publicly available dataset and has a multitude of labels. The semantic mask are extrated from the 2017 Panoptic annotations. This set contains more than 100k images that are densly annotated with both the semantic class and instance. There are a total of 133 different classes which belong to 27 `supercategories'. The four categories ``food'' and ``food-stuff'' and ``furniture'' and ``furniture-stuff'' were merged into ``food'' and ``furniture'' respectively, bringing the number of supercategories to 25. To speed up convergences, we will use these 25 classes. The distribution of the class labels can be seen in Figure \ref{fig:coco-class-distribution}. Some samples of the dataset can be seen in Figure \ref{fig:coco-samples}. More samples can be found in Appendix \ref{appendix:coco_samples}. 


\begin{figure}[h]
    \centering
    \includegraphics[width=0.9\textwidth]{figures/datasets/coco/class_distribution.png}
    \caption{Class Distribution of CoCo}
    \label{fig:coco-class-distribution}
\end{figure}

\begin{figure}
    \centering
    \subfloat[Training sample 0]{%
        \includegraphics[width=0.5\textwidth]{figures/datasets/coco/samples/train/0.png}%
    }
    \subfloat[Training sample 1]{%
        \includegraphics[width=0.5\textwidth]{figures/datasets/coco/samples/train/1.png}%
    }\\
    \subfloat[Validation sample 0]{%
        \includegraphics[width=0.5\textwidth]{figures/datasets/coco/samples/val/0.png}%
    }
    \subfloat[Validation sample 1]{%
        \includegraphics[width=0.5\textwidth]{figures/datasets/coco/samples/val/1.png}%
    }
    \caption{\label{fig:coco-samples}Ground truths for the dataset samples}
\end{figure}


\subsection{Training Settings}
All models are implemented in PyTorch~\cite{Ansel_PyTorch_2_Faster_2024} using an adapted version of the segmentation models repository~\cite{Iakubovskii:2019}. All code and configurations required to train the models and reproduce the experiments can be found on github \footnote[1]{\url{https://github.com/Generative-AI-TUe/msc-project-1297333}}. All models are trained on a NVIDIA Geforce RTX 2080 TI. The gradients are clipped using the norm, with a maximum value of 10. The AdaMax~\cite{kingma2017adammethodstochasticoptimization} is used with a cosine annealing learning rate, varying between $1e^{-3}$ and $1e^{-4}$. Each model is trained on 10.000 minibatches of size 96, unless otherwise specified.


\section{Is pre-training beneficial?}
For the experiments we make use of our method, VAES, FPN, and U-Net. Each model was trained eight times with different configurations. We used different settings for the pre-trained weights:
\begin{itemize}
    \item Without (`None') pre-trained weights.
    \item With pre-trained weights retrieved from classification of ImageNet.
    \item With pre-trained weights retrieved from a $\beta$-vae, with $\beta=1$ and $\beta=100$.
\end{itemize}
Additionally, the model is trained with `frozen' encoder weights (the encoder weights are not updated), and with `unfrozen' encoder weights (the encoder weights are updated). The resulting Evaluation Jaccard Index can be seen in Table~\ref{tab:baseline_results}.

\input{figures/baselines/baselines-results}

\todo{TODO: Run statistical analysis on results.}
\begin{itemize}
    \item Compare {all}-vae1-frozen to {all}-img-frozen
    \item Compare {all}-vae1-unfrozen to {all}-{rand, img}-unfrozen
\end{itemize}

Include the current image
\begin{figure}[h]
    \foreach \i in {0,1,...,4} {
            \centering
            \subfloat[Image]{\includegraphics[width=0.2\textwidth]{figures/baselines/samples/VAES-imagenet-False/\i.png}}
            \subfloat[Ground Truth]{\includegraphics[width=0.2\textwidth]{figures/baselines/samples/VAES-imagenet-False/gt_\i.png}}
            \subfloat[VAES-imagenet]{\includegraphics[width=0.2\textwidth]{figures/baselines/samples/VAES-imagenet-False/pr_\i.png}}
            \subfloat[unet-imagenet]{\includegraphics[width=0.2\textwidth]{figures/baselines/samples/unet-imagenet-False/pr_\i.png}}
            \subfloat[fpn-imagenet]{\includegraphics[width=0.2\textwidth]{figures/baselines/samples/fpn-imagenet-False/pr_\i.png}}
            \\
        }
    \caption{Samples of the validation dataset, with the ground truth and the prediction by the model. The encoder is not frozen. (Note: FPN Result is not the correct image yet)}\label{ref:baseline-sample-results-0}
\end{figure}


\section{Reduction data required}
To determine if pre-training results in a reduction of labeled training data required, a full factorial design is done over the parameters: architecture type, pre-trained weights, and the percentage of the (labeled) dataset used. The resulting Evaluation Jaccard Index of each model configuration can be seen in Table~\ref{tab:data_fraction_results} and are plotted in Figure~\ref{fig:dataset-fraction-results}.
\input{figures/data_percentage/results_dataset_fraction}

\begin{figure}[h]
    \centering
    \includegraphics[width=0.9\textwidth]{figures/data_percentage/line-plot.png}
    \caption{Jaccard Index for reduced training dataset size.}
    \label{fig:dataset-fraction-results}
\end{figure}

An Analysis of Variance (ANOVA) is done, of which the results can be seen in Table~\ref{tab:data_fraction_parameter_significance}. Based on these results, it can be determined that there are no significant interaction effects between any of the parameters, and that each individual parameter has a significant effect.
\input{figures/data_percentage/parameter_significance_table}

The effect of the parameters can then be analysed by a simple OLS model. The results of which are shown in Table~\ref{tab:data_fraction_parameter_influence}. It shows that there is a large and significant increase in performance when using the ImageNet weights. The weights gained from pre-training a VAE do not significantly affect the performance, compared to random weights. Furthermore, both the FPN and UNet architectures are better than the VAES architecture. Finally, the size of the dataset is significant, however it is more important to choose the right architecture and especially pre-trained weights.
\input{figures/data_percentage/parameter_influence_table}


\section{Ablation Study}
\subsection{Influence of the backbone}
We first analyse the influence of the backbone on the performance of the VAE task by comparing the following backbones, MobilenetV2~\cite{sandler2019mobilenetv2invertedresidualslinear}, EfficientNet~\cite{tan2020efficientnetrethinkingmodelscaling} and Resnet50~\cite{he2015deep}. The results can be seen in Table \ref{tab:vae-backbones}. Some examples of the reconstruction capabillities can be seen in Figure \ref{fig:vae-backbones}

\begin{table}[!ht]
    \centering
    \caption{Loss values resulting from training a Beta-VAE for various $\beta$ values}
    \label{tab:vae-backbones}
    \begin{tabular}{ccc}
        \hline
        $\beta$ & Kl-Divergence & Reconstruction Error (x1e5) \\
        \hline
        0.01    & 80200         & 1.9                         \\
        0.1     & 31250         & 1.5                         \\
        1       & 8190          & 2.7                         \\
        10      & 2089          & 2.2                         \\
        100     & n.a.          & (node crashed mid run)      \\
        \hline
    \end{tabular}
\end{table}

\begin{figure}[!ht]
    \centering
    \caption{Example reconstruction for a few of the models}
    \label{fig:vae-backbones}
    \subfloat[Original, $\beta$ = 0.01]{\includegraphics[width=0.45\linewidth]{figures/beta-vae/b0.01-0.png}}
    \subfloat[Original, $\beta$ = 0.1]{\includegraphics[width=0.45\linewidth]{figures/beta-vae/b0.1-0.png}} \quad
    \subfloat[Original, $\beta$ = 1]{\includegraphics[width=0.45\linewidth]{figures/beta-vae/b1-0.png}}
    \subfloat[Original, $\beta$ = 10]{\includegraphics[width=0.45\linewidth]{figures/beta-vae/b10-0.png}}
\end{figure}


\subsection{Influence of the Beta factor}
We also analyse the effect of the beta factor on the reconstruction quality of the vae. This is done by training models with varying values for beta. The results can be seen in Table \ref{tab:beta-vae-loss-values}. Some examples of the reconstruction capabillities can be seen in Figure \ref{fig:beta-vae-recon-examples}.

\begin{table}[!ht]
    \centering
    \caption{Loss values resulting from training a Beta-VAE for various $\beta$ values}
    \label{tab:beta-vae-loss-values}
    \begin{tabular}{ccc}
        \hline
        $\beta$ & Kl-Divergence & Reconstruction Error (x1e5) \\
        \hline
        0.01    & 80200         & 1.9                         \\
        0.1     & 31250         & 1.5                         \\
        1       & 8190          & 2.7                         \\
        10      & 2089          & 2.2                         \\
        100     & 498           & 2.9                         \\
        \hline
    \end{tabular}
\end{table}

\begin{figure}[!ht]
    \centering
    \caption{Example reconstructions for $\beta$-vae.}
    \label{fig:beta-vae-recon-examples}
    \subfloat[Original, $\beta$ = 0.01]{\includegraphics[width=0.45\linewidth]{figures/beta-vae/b0.01-0.png}}
    \subfloat[Original, $\beta$ = 0.1]{\includegraphics[width=0.45\linewidth]{figures/beta-vae/b0.1-0.png}} \quad
    \subfloat[Original, $\beta$ = 1]{\includegraphics[width=0.45\linewidth]{figures/beta-vae/b1-0.png}}
    \subfloat[Original, $\beta$ = 10]{\includegraphics[width=0.45\linewidth]{figures/beta-vae/b10-0.png}}
\end{figure}


\subsection{Skip Connection}
To understand the importance of the skip connections which are added after the pre-training. We will show the effect of this by incrementally removing more skip connections.
\todo{Training is in the backlog of slurm}

\begin{table}[!ht]
    \centering
    \caption{Results when removing skip connections.}
    \label{tab:abl-skip-connection}
    \begin{tabular}{cccc}
        \hline
        Num Skip Connections & CrossLoss (x1e6) & Eval JI & Train JI \\
        \hline
        0 (Only midblock)    & n.a.             & n.a.    & n.a.     \\
        1                    & n.a.             & n.a.    & n.a.     \\
        2                    & n.a.             & n.a.    & n.a.     \\
        3                    & n.a.             & n.a.    & n.a.     \\
        4                    & n.a.             & n.a.    & n.a.     \\
        5 (all)              & n.a.             & n.a.    & n.a.     \\
        \hline
    \end{tabular}
\end{table}
