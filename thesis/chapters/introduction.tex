\chapter{Introduction}\label{chapter:introduction}

Mobile robotics is a rapidly growing field that has numerous applications in industries such as logistics, agriculture, and healthcare~\cite{cognominal2021evolving,kebede2024review,clark2023amazon}. With the increasing demand for efficient and autonomous mobile robots, researchers have been exploring various techniques to improve their performance. One of the major challenges is the autonomous navigation in unknown environments~\cite{alatise2020review}. It requires the robot to create a map of the environment while traversing it. The second difficulty is to properly understand its position relative to the map. An algorithm that is capable of doing this is Simultanious Localization and Mapping (SLAM)~\cite{whyte1996slam,whyte2006slam}. It, in theory, solves the problem of exploring an unknown environment, while simultaniously allowing the robot to locate itself in that environment. Thus allowing it to navigated this environment. However, in practice, there still exist a many challenges. One of these challenges is the detection of robust landmarks, to which the robot relate its own position aswell as that of other objects that it tries to map. The problem is made even more difficult when the map in which the robot navigates is not stationary, but dynamic. In these dynamic environments the position of some the objects around it will also move and thus are not appropiate to be used as landmarks. Moreover, for these robots to be able to quickly react to external influences they need to be able to process all this information in real-time. Which is made extra challenging due to the energy and size constraints that many practical applications put on the physical design of the robot.

With the rise of small gpu accelerated computers, such as the NVIDIA Jetson Orin~\cite{NVIDIA_Karumbunathan_2022}, computer vision has become feasible to be ran in real-time applications with limited power. This made vision based SLAM algorithms, which use computer vision to detect landmarks, feasible for mobile robots. One such algorithm is the Dynamic Semantic SLAM~\cite{yu2018ds} (DS-SLAM). It uses SegNet~\cite{badri2017segnet}, a semantic segmentation network, that is able to classify each pixel in a given frame. These classifications can subsequently be used to remove landmarks that are not reliable due to being non-stationary. However, these machine learning algorithms often fail when the data they encounter in production is different from their training data~\cite{Goodfellow-et-al-2016,ozdag2018adversarial,warde201611,10.14778/3632093.3632098,DBLP:journals/corr/KurakinGB16a,10.1145/3422622}. Therefor, collecting data that is representative for the environment in which the robot will operate is important. Although the collection of this raw data can often be done. Converting it into a useable dataset on which machine learning algorithms can be trained often requires manual labour. One solution, is to make use of unsupervised learning methods, which do not require labeled data. One algorithm that can learn from unlabeled data is the Variational Auto Encoder~\cite{kingma2014autoencodingvariationalbayes}. However, this model is not able to produce (semantic) segmentation masks. This thesis will investigate if it is possible to make use of unsupervised pre-training to reduce the amount of labeled data that is required. Thus reducing the cost of deploying robots to new environments.

\section{Research Questions and Contributions}
This thesis will answer the following research questions.
\begin{itemize}
    \item Can the VAE be adaptes
\end{itemize}
The contributions of this thesis are as follows;
\begin{itemize}
    \item The (semantic) segmentation task is reformulated as a probabilistic model, enabling it to be tackled from a generative modeling perspective.
    \item An adaption of the VAE, the VAE-Segmentation architecture, is proposed. A variational  can be used to produce semantic segmentation masks.
    \item It is shown that using pretrained weights can increase the performance of semantic segmentation models. Having a bigger effect on the final performance compared to the model architecture. Furthermore it is shown, that the VAE reconstruction tasks 
\end{itemize}
Then we will show that the classic VAE tasks does not provide useful features for semantic segmentation. Finally, we will statistically proof that the most important factor in achieving good results is not necesarrily the amount of data for the task at hand, but adpating a model that is trained on a large classification dataset can provide huge improvements to the resulting network.
