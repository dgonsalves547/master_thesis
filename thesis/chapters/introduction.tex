\chapter{Introduction}\label{chapter:introduction}

Mobile robotics is a rapidly growing field that has numerous applications in industries such as logistics, agriculture, and healthcare~\cite{cognominal2021evolving,kebede2024review,clark2023amazon}. With the increasing demand for efficient and autonomous mobile robots, researchers have explored various techniques to improve their performance. One of the major challenges is autonomous navigation in unknown environments~\cite{alatise2020review}. It requires the robot to create a map of the environment while traversing it. Another difficulty is properly understanding its position relative to the map. An algorithm that is capable of doing this is Simultaneous Localization and Mapping (SLAM)~\cite{whyte1996slam,whyte2006slam}. It, in theory, solves the problem of exploring an unknown environment, while simultaneously allowing the robot to locate itself in that environment. Thus allowing it to navigate this environment. However, in practice, there still exist many challenges. One of these challenges is the detection of robust landmarks, to which the robot relates its own position as well as that of other objects that it tries to map. The problem is made even more difficult when the map in which the robot navigates is not stationary, but dynamic. In these dynamic environments, the position of some of the objects around it will also move and thus are not appropriate to be used as landmarks. Moreover, for these robots to be able to quickly react to external influences they need to be able to process all this information in real-time. This is made extra challenging due to the energy and size constraints that many practical applications put on the physical design of the robot.

With the rise of small GPU-accelerated computers, such as the NVIDIA Jetson Orin~\cite{NVIDIA_Karumbunathan_2022}, computer vision has become feasible to run in real-time applications with limited power. This made vision-based SLAM algorithms, which use computer vision to detect landmarks, feasible for mobile robots. One such algorithm is the Dynamic Semantic SLAM~\cite{yu2018ds} (DS-SLAM). It uses SegNet~\cite{badri2017segnet}, a semantic segmentation network, that is able to classify each pixel in a given frame. These classifications can subsequently be used to remove landmarks that are not reliable due to being non-stationary. However, these machine learning algorithms often fail when the data they encounter in production is different from their training data~\cite{Goodfellow-et-al-2016,ozdag2018adversarial,warde201611,10.14778/3632093.3632098,DBLP:journals/corr/KurakinGB16a,10.1145/3422622}. Therefore, collecting data that is representative of the environment in which the robot will operate is important. Although the collection of this raw data can often be done. Converting it into a usable dataset on which machine learning algorithms can be trained often requires manual labour. One solution is to make use of unsupervised learning methods, which do not require labeled data. One algorithm that can learn from unlabeled data is the Variational Auto Encoder~\cite{kingma2014autoencodingvariationalbayes}. However, this model is not able to produce (semantic) segmentation masks. This thesis will investigate if it is possible to make use of unsupervised pre-training to reduce the amount of labeled data that is required. Thus reducing the cost of deploying robots to new environments.

\section{Research Questions and Contributions}
This thesis will answer the following research questions.
\begin{itemize}
    \item Can the VAE be adapted to an Image Segmentation task?
    \item Do the pre-trained weights of a VAE provide useful features for image segmentation?
    \item Does pre-training on the VAE task reduce the amount of labeled data required?
\end{itemize}
The contributions of this thesis are as follows;
\begin{itemize}
    \item The (semantic) segmentation task is reformulated as a probabilistic model, enabling it to be tackled from a generative modeling perspective.
    \item An adaption of the VAE, the VAE-Segmentation architecture, is proposed. A variational model can be used to produce semantic segmentation masks.
    \item It is shown that using pre-trained weights can increase the performance of semantic segmentation models. Having a bigger effect on the final performance compared to the model architecture.
    \item  Furthermore it is shown, that the VAE reconstruction tasks do not provide features that are significantly better than training from scratch.
\end{itemize}
