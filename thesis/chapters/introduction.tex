\chapter{Introduction}\label{chapter:introduction}

Deep learning models require a lot of (labeled) data, and are often computationally intensive. Although data is easily acquirable, the labeling process is labor intensive and thus expensive. Thus if the unlabeled data can be used to prime a model, it will require less labeled data to finetune on the specific task required. In the context of mobile robotics it is furthermore important to have a low computational cost for inference, such that the inference can happen on the edge. Finally, it is important that the robotic devices can handle unexpected situations safely. The first step towards that is recognizing model failures. When the uncertainty of our model can be correctly estimated, it can be used as a proxy for unknown situations, which then can be used to take precautions.

\subsubsection*{Are VAEs suitable for Semantic/Panoptic segmentation, in the context of mobile robotics?}
Variational Autoencoders (VAE) can be used to do bootstrapping, as shown in \cite{kohl2018probabilistic}. Furthermore VAEs have cheaper inference cost compared to diffusion models. In this thesis, a model will be trained showing that VAEs can be used for semantic segmenation.

\subsubsection*{Does pretraining on (unlabeled) data reduce the required amount of labeled data?}
The labeling of data by humans is very costly, and often the bottleneck of improving models. Because the encoder of a VAE can be pretrained with unlabeled data, we hypothesis that this will reduce the amount of data that needs to be labeled. We take special intrest for the two possible cases:
\begin{itemize}
    \item Unlabeled data from the same data distribution (Simulated by taking the entire dataset for pretraining and a subset for finetuning)
    \item Unlabeled data from a different data distribution (Simulated by taking a different dataset for the pretraining)
\end{itemize}
