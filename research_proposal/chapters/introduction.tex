\section{Overall aim and goals}\label{sec:goals}
The main goal of this thesis will be the implementation of a (generative) Object Detection model that is able to provide reliable uncertainty estimates on its own predictions. Secondary to that,
\begin{itemize}
    \item Create a (generative) model which can predict bounding boxes with Uncertainty Quantification.
          \subitem i.e. Detecting weird combinations of objects within a scene
    \item Validate uncertainty of the model.
          \subitem Does certainty and precision correlate. (Statistical analyses)
    \item Test uncertainty as measure for active learning.
          \subitem To make more efficient use of human labelers. One possibility is to take a subset of e.g. 10\% of a labeled dataset, and then iteratively select more data. Comparing it to a random subset of equal size.
    \item Verify uncertainty is a good predictor for OoD data.
    \item Design a system which can make efficient use of uncertainty of previous stages.
\end{itemize}


\subsection{Possible RQs}
Current Ideas for possible RQs. (For the seminar we need to have (at least) 5 RQs, they do not need to all be answered)

\begin{itemize}
    \item Can generative models be used for uncertainty prediction in Object Detection?
    \item Does increasing the iterations of a generative model decrease the uncertainty?
    \item Is uncertainty a good indicator for active learning?
    \item Is uncertainty a good indicator for relabeling?
    \item Can temporal data be used to improve Uncertainty Quantification?
\end{itemize}

%%------------------------------------------------------------------------------
\subsection{Motivation and Challenges}

Artificial Intelligence solutions are increasingly put in new and challenging scenarios. They are known to work well when the training and inference set are from the same distribution \cite{krizhevsky2012imagenet}. However, it has been shown that models will predict with high scores for inputs that are not relevant \cite{Nguyen_2015_CVPR,szegedy2013intriguing}. It has also been shown that this can be used to attack these networks\cite{goodfellow2014explaining,dong2018boosting}.
Uncertainty Quantification (UQ) can enable a system to detect when a prediction might be of lesser quality \cite{dÃ¤ubener2020detecting}, and allow it to preemptively react to that\cite{osti_1481629}. Either by stopping or requesting human intervention.
Furthermore, understanding when models are uncertain, allows for more effective data sampling and labeling by making use of active learning schemes \cite{settles2009active,Bernhardt_2022,yang2009effective}. The latter is especially useful in industries where labeling is expensive or time-consuming.

Object Detection is an especially difficult field as the model has many outputs of different types. It requires both regression (for localization) and classification \cite{Gasperini_2022}. Moreover, there are multiple uncertainties present:
\begin{itemize}
    \item Objectness: \t Is a bounding box an object (of interests)?
    \item Classification: \t Is a bounding box of a certain class?
    \item Size: \t Is the size of the bounding box correct?
    \item Location: \t Is the location of the bounding box correct?
\end{itemize}


%%------------------------------------------------------------------------------
\subsection{Broad Literature Analysis}\label{sec:broadliterature}

This project covers broader research areas, each will be covered separately in subsections \ref{sec:broadliterature:uncertainty} and \ref{sec:broadliterature:object_detection}. Related work in the combination will be described in subsection \ref{sec:broadliterature:combination}

\subsubsection{Uncertainty Quantification}\label{sec:broadliterature:uncertainty}
The ability to distinguish certain and uncertain outputs from machine learning models is useful for various reasons. It can be used for active learning \cite{yang2009effective,settles2009active,houlsby2011bayesian,Bernhardt_2022}, which makes better use of limited labeling capacity.

\citep{gal2016uncertainty} distinguishes two kinds of uncertainty. Aleatoric uncertainty, the uncertainty that is caused by imprecise input data, and epistemic uncertainty, the uncertainty that is caused by the model. Aleatoric uncertainty is often caused by imprecise measurements and can be reduced by improving the quality of our dataset and inputs. The latter, epistemic uncertainty, can be reduced by improving either the training procedure, increasing the amount of data or improving the model architecture.

Uncertainty Quantification (UQ) is an important factor to increase the trust in automated processes based on machine learning. Current methods often sample from existing networks \cite{gal2016dropout,NEURIPS2019_118921ef,miller2019evaluating} or predict parameters of a distribution \cite{choi2019gaussian,swiatkowski2020ktied}.


\subsubsection{Object Detection}\label{sec:broadliterature:object_detection}

% Most object detection models consist of an image classification backbone such as VGG16 \cite{simonyan2014very}, MobileNet \cite{howard2017mobilenets} or ResNet \cite{he2015deep}.
There are two main paradigms within Object Detection, One-Stage detectors\cite{zhou2019objects, bochkovskiy2020yolov4, wang2022yolov7, liu2016ssd, duan2019centernet}, which directly predict both the bounding box and class in a single forward pass, and Multi-Stage detectors \cite{girshick2014rich, girshick2015fast}, which first detect regions of interests to then subsequently classify these regions. A more recent development is DiffusionDet \cite{chen2023diffusiondet}, which iteratively 'de-noises' a set of random bounding boxes towards the ground truth bounding boxes. Furthermore, there are some general tricks that have shown to provide improved performance at the cost of an increased training time for most object detection algorithms. These have been dubbed "Bag of Freebies" by \citep*{zhang2019bag}, as they do not increase inference time.

\paragraph*{One-Stage Detectors}
The Single Shot Detector proposed by \citep{liu2016ssd} makes use of many anchor boxes. For each anchor box an offset and class is predicted, which are subsequently merged using Non-Max-Suppression (NMS). During training all bounding boxes with an Intersection over Union (IoU) greater than a threshold are matched and should be predicted with that class. All unmatched boxes should be classified as a `background' class. This leads to a huge class imbalance. To tackle this, hard negative mining is used. For every positive match, at most $n$ (in the paper 3) negative boxes are included during the loss calculation.




\subsubsection{In combination}\label{sec:broadliterature:combination}
The combination of Uncertainty Quantification and Object Detection is especially difficult as Object Detection is both a regression and a classification task.

\cite{Gasperini_2022}

%%------------------------------------------------------------------------------
\subsection{Formulation of the problem and objectives}
\paragraph*{Model formulation}
Let $x \in \mathbb{R}^{HxWxC}$ be the input image which contains objects $O_i$, which are a combination of a bounding box: $B_i \in \mathbb{R}^{N4}$ and a class $c \in C$.

\paragraph*{Metric formulation}

\todo{Mathematically formulate the following metrics}
\begin{itemize}
    \item IoU
    \item mean Average Precision
    \item Uncertainty Error \cite{miller2019evaluating}
    \item (AU)ROC \cite{miller2019evaluating}
    \item (AU)Precision-Recall \cite{saito2015pr}
\end{itemize}

\todo{Formulate (uncertainty) Metrics}

% Include a description of the overall aim and key objectives. Explain your research questions as well as possible. Identify potential general tasks that will need to be tackled in order to complete the project successfully.

% As a general rule-of-thumb, a potential evaluator would be asked to summarise the strong and weak points of the proposal as a whole. They will consider the strengths and weaknesses in such a way that they are comprehensible and substantiated for a broader scientific group. They will assess the quality, innovative character and academic impact of the proposal, including the challenging content, originality of the topic, scientific elements, potential to make an important contribution, effectiveness of proposed methodology, importance of the proposed research topic, etc.

%% THESE CITATION (nocite) ARE USED ONLY TO ILLUSTRATE THE REFERENCES. YOU SHOULD USE \cite (OR THE APPROPRIATE DERIVATION SUCH AS \citep \citet etc) WITHIN YOUR TEXT AS NEEDED
% \nocite{arias2016scalable}
% \nocite{batal2013efficient}
% \nocite{bi2013inferring}
% \nocite{bielza2011multi}

% \begin{figure}[!h]
%     \begin{center}

%         \begin{tikzpicture}[align = center, node distance=30mm, thick, main/.style = {draw, circle}]
%             \node[main, fill=green] (x1) {$X_1$};
%             \node[main, fill=green] (x2) [right of=x1] {$X_2$};
%             \node[main, fill=green] (x3) [right of=x2] {$X_3$};
%             \node[main, fill=green] (x4) [right of=x3] {$X_4$};
%             \node[main, fill=green] (x5) [right of=x4] {$X_5$};
%             \node[main, fill=cyan] (y1) [above right of=x1] {$\bar{Y}_1$};
%             \node[main, fill=cyan] (y2) [above right of=x2] {$\bar{Y}_2$};
%             \node[main, fill=cyan] (y3) [above right of=x3] {$\bar{Y}_3$};
%             \node[main, fill=cyan] (y4) [above right of=x4] {$\bar{Y}_4$};
%             \draw[draw=black,->] (y1) -- (x1);
%             \draw[draw=black,->] (y2) -- (x2);
%             \draw[draw=black,->] (y2) -- (x3);
%             \draw[draw=black,->] (y3) -- (x4);
%             \draw[draw=black,->] (y4) -- (x4);
%             \draw[draw=black,->] (y4) -- (x5);
%             \draw[draw=black,->] (x2) -- (x1);
%             \draw[draw=black,->] (x2) -- (x3);
%             \draw[draw=black,->] (x4) -- (x3);
%             \draw[draw=black,->] (x5) -- (x4);
%             \draw [draw=black,-latex] (x5) to [bend left=20] (x3);
%             \draw[draw=cyan,->] (y1) -- (y2);
%             \draw[draw=cyan,->] (y3) -- (y4);
%         \end{tikzpicture}

%         \caption{Just an example of graph using tikz, by V.L.Nguyen.}
%         \label{fig:examplegraph}
%     \end{center}
% \end{figure}