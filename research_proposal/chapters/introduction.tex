\section{Overall aim and goals}\label{sec:goals}
The main goal of this thesis will be the implementation of a (generative) Object Detection model for mobile robotics. An important part of this is the ability to recognize novel objects. Furthermore, it is important to be able to have a good understanding of the quality of the prediction. As it is well known that Neural Networks often perform bad when presented with Out-of-Distribution (OoD) data.\todo{Possibly add citation for this statement} As mobile robotics are required to navigate unknown terrain, it is important that the model is capable of handling OoD data. This can be achieved either by ensuring the model is robust against OoD data or enabling the model to warn the user when OoD data is detected.

% To achieve the above-mentioned goal 
% \begin{itemize}
%     \item A (generative) model which can predict bounding boxes with Uncertainty Quantification.
%     \item Detecting unexpected combinations of objects within a scene
%     \item Validate uncertainty of the model.
%           \subitem Does certainty and precision correlate. (Statistical analyses)
%     \item Test uncertainty as measure for active learning.
%           \subitem To make more efficient use of human labelers. One possibility is to take a subset of e.g. 10\% of a labeled dataset, and then iteratively select more data. Comparing it to a random subset of equal size.
%     \item Verify uncertainty is a good predictor for OoD data.
%     \item Design a system which can make efficient use of uncertainty of previous stages.
% \end{itemize}



\subsection{Research questions}
\todo{Possibly move this to after motivation and challenges}
To achieve the above-mentioned goal I will try to answer the following research questions:

\begin{itemize}
    \item Is it possible to detect novel objects using Generative Object Detection?
    \item Is it possible to do uncertainty quantification for the various aspects of object detection in a single model?
          \subitem How likely is a bounding box an object?
          \subitem How likely is an object of a specific class?
          \subitem What is the uncertainty of the objects size?
    \item What is the performance difference between SOTA Object Detection models and a Generative Object Detection model acceptable?
    \item Is the uncertainty quantification given by the Generative model an useful indicator ...
          \subitem for active learning?
          \subitem detecting wrongly labeled items?
    \item Can temporal data be used to improve Uncertainty Quantification?
\end{itemize}

%%------------------------------------------------------------------------------
\subsection{Motivation and Challenges}

Artificial Intelligence solutions are increasingly put in new and challenging scenarios. They are known to work well when the training and inference set are from the same distribution \cite{krizhevsky2012imagenet}. However, it has been shown that models will predict with high scores for inputs that are not relevant \cite{Nguyen_2015_CVPR,szegedy2013intriguing}. It has also been shown that this can be used to attack these networks\cite{goodfellow2014explaining,dong2018boosting}.
Uncertainty Quantification (UQ) can enable a system to detect when a prediction might be of lesser quality \cite{dÃ¤ubener2020detecting}, and allow it to preemptively react to that\cite{osti_1481629}. Either by stopping or requesting human intervention.
Furthermore, understanding when models are uncertain, allows for more effective data sampling and labeling by making use of active learning schemes \cite{settles2009active,Bernhardt_2022,yang2009effective}. The latter is especially useful in industries where labeling is expensive or time-consuming.

Object Detection is an especially difficult field as the model has many outputs of different types. It requires both regression (for localization) and classification \cite{Gasperini_2022}. Moreover, there are multiple uncertainties present:
\begin{itemize}
    \item Objectness: \t Is a bounding box an object?  \label{prop:Objectness}
    \item Classification: \t Is a bounding box of a certain class? \label{prop:Classification}
    \item Size: \t Is the size of the bounding box correct? \label{prop:Size}
    \item Location: \t Is the location of the bounding box correct? \label{prop:Location}
\end{itemize}


%%------------------------------------------------------------------------------
\subsection{Broad Literature Analysis}\label{sec:broadliterature}

This project covers broader research areas, each will be covered separately in subsections \ref{sec:broadliterature:uncertainty} and \ref{sec:broadliterature:object_detection}. Related work in the combination will be described in subsection \ref{sec:broadliterature:combination}

\subsubsection{Uncertainty Quantification}\label{sec:broadliterature:uncertainty}
The ability to distinguish certain and uncertain outputs from machine learning models is useful for various reasons. It can be used for active learning \cite{yang2009effective,settles2009active,houlsby2011bayesian,Bernhardt_2022}, which makes better use of limited labeling capacity.

\citep{gal2016uncertainty} distinguishes two kinds of uncertainty. Aleatoric uncertainty, the uncertainty that is caused by imprecise input data, and epistemic uncertainty, the uncertainty that is caused by the model. Aleatoric uncertainty is often caused by imprecise measurements and can be reduced by improving the quality of our dataset and inputs. The latter, epistemic uncertainty, can be reduced by improving either the training procedure, increasing the amount of data or improving the model architecture.

Uncertainty Quantification (UQ) is an important factor to increase the trust in automated processes based on machine learning. Current methods often sample from existing networks \cite{gal2016dropout,NEURIPS2019_118921ef,miller2019evaluating} or predict parameters of a distribution \cite{choi2019gaussian,swiatkowski2020ktied}.


\subsubsection{Object Detection}\label{sec:broadliterature:object_detection}

% Most object detection models consist of an image classification backbone such as VGG16 \cite{simonyan2014very}, MobileNet \cite{howard2017mobilenets} or ResNet \cite{he2015deep}.
There are two main paradigms within Object Detection, One-Stage detectors\cite{zhou2019objects, bochkovskiy2020yolov4, wang2022yolov7, liu2016ssd, duan2019centernet}, which directly predict both the bounding box and class in a single forward pass, and Multi-Stage detectors \cite{girshick2014rich, girshick2015fast}, which first detect regions of interests to then subsequently classify these regions. A more recent development is DiffusionDet \cite{chen2023diffusiondet}, which iteratively 'de-noises' a set of random bounding boxes towards the ground truth bounding boxes. Furthermore, there are some general tricks that have shown to provide improved performance at the cost of an increased training time for most object detection algorithms. These have been dubbed "Bag of Freebies" by \citep*{zhang2019bag}, as they do not increase inference time.

\paragraph*{One-Stage Detectors}
The Single Shot Detector proposed by \citep{liu2016ssd} makes use of many anchor boxes. For each anchor box an offset and class is predicted, which are subsequently merged using Non-Max-Suppression (NMS). During training all bounding boxes with an Intersection over Union (IoU) greater than a threshold are matched and should be predicted with that class. All unmatched boxes should be classified as a `background' class. This leads to a huge class imbalance. To tackle this, hard negative mining is used. For every positive match, at most $n$ (in the paper 3) negative boxes are included during the loss calculation.

\paragraph*{Multi-Stage Detectors}
\todo{Expand the multi-stage detector part}

\paragraph*{Self-supervised}
Recent developments in Vision Transformers (ViT) \cite{dosovitskiy2021image} have been used to pre-train backends for object detection tasks \cite{carion2020endtoend}. The benefit of ViT is the ability to use unlabeled data to pre-train the transformer part of the model. A relatively small fine-tuning dataset can then be used to train the model for a specific task. They have also been shown to segment objects in a fully self-supervised way \cite{caron2021emerging}.

\subsubsection{In combination}\label{sec:broadliterature:combination}
The combination of Uncertainty Quantification and Object Detection is especially difficult as Object Detection is both a regression and a classification task. A recent advancement in this is CertainNet \cite{Gasperini_2022}. Which is capable of providing sample free certainty estimations on the various aspects of the prediction.

%%------------------------------------------------------------------------------
\subsection{Formulation of the problem and objectives}
\paragraph*{Model formulation}
Let $x \in \mathbb{R}^{H\times W\times C}$ be the input image which contains objects $\mathcal{O}$. Each object $o_i$ is a combination of a bounding box: $b_i \in \mathbb{R}^{4}$ and a class $c_i \in C$.

A one-stage discriminative model for object detection can often be described by the following function:
\begin{align}
    f_{\theta}(x) & = \mathcal{O}                                             \\
                  & = \mathbb{R}^{(4 + |C|) \times |O|} \label{eq:size_of_o}  \\
                  & = NMS(\mathbb{R}^{(4 + |C| + 1) \times N}) \label{eq:nms}
\end{align}
At Equation \ref{eq:size_of_o} $|\mathcal{O}|$ is not known (or constant). This is usually solved by taking $N >> \max{|\mathcal{O}|}$\cite{bochkovskiy2020yolov4, wang2022yolov7, liu2016ssd}, and adding an extra 'negative' class. $\mathcal{O}$ is then extracted using Non-maximum Suppression (NMS).

In a generative context the problem can be described by $p(\mathbf{x}, \mathcal{O})$, which can be decomposed into:
\begin{align}
    p(\mathbf{x}, \mathcal{O}) & = p(\mathbf{x}) \cdot p(\mathbf{\mathcal{O}} | \mathbf{x}) \label{eq:generative_model}                                                \\
                               & = p(\mathbf{x})\prod_{\mathbf{i} = 0}^{|\mathcal{O}|}p(\mathbf{o_i} \mid \mathbf{x} \cap \mathbf{o_0} \cap ... \cap \mathbf{o_{i-1}}) \\
\end{align}

\paragraph*{Metric formulation}
Current SOTA models report on the following metrics:
\begin{itemize}
    \item IoU
    \item mean Average Precision
    \item Uncertainty Error \cite{miller2019evaluating}
    \item (AU)ROC \cite{miller2019evaluating}
    \item (AU)Precision-Recall \cite{saito2015pr}
\end{itemize}

% Include a description of the overall aim and key objectives. Explain your research questions as well as possible. Identify potential general tasks that will need to be tackled in order to complete the project successfully.

% As a general rule-of-thumb, a potential evaluator would be asked to summarise the strong and weak points of the proposal as a whole. They will consider the strengths and weaknesses in such a way that they are comprehensible and substantiated for a broader scientific group. They will assess the quality, innovative character and academic impact of the proposal, including the challenging content, originality of the topic, scientific elements, potential to make an important contribution, effectiveness of proposed methodology, importance of the proposed research topic, etc.
